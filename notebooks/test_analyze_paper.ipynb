{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import feedparser\n",
    "\n",
    "def clean_text(x):\n",
    "    \n",
    "    # Replace newline characters with a space\n",
    "    new_text = \" \".join([c.strip() for c in x.replace(\"\\n\", \"\").split()])\n",
    "    # Remove leading and trailing spaces\n",
    "    new_text = new_text.strip()\n",
    "    \n",
    "    return new_text\n",
    "\n",
    "\n",
    "def get_daily_arxiv_papers():\n",
    "    max_results = 100\n",
    "    # categories = ['cs.AI', 'cs.CV', 'cs.IR', 'cs.LG', 'cs.CL']\n",
    "    categories = ['cs.CV']\n",
    "    base_url = 'http://export.arxiv.org/api/query?'\n",
    "    all_categories = [f'cat:{category}' for category in categories]\n",
    "    search_query = '+OR+'.join(all_categories)\n",
    "    \n",
    "    paper_list = []\n",
    "    start = 0\n",
    "    today = datetime.utcnow().date()\n",
    "    new_papers_found = True\n",
    "    wait_time = 3\n",
    "\n",
    "    while new_papers_found:\n",
    "        query = f'search_query={search_query}&start={start}&max_results={max_results}&sortBy=submittedDate&sortOrder=descending'\n",
    "        response = requests.get(base_url + query)\n",
    "        feed = feedparser.parse(response.content)\n",
    "        new_paper = 0\n",
    "        for r in feed.entries:\n",
    "            paper_date = datetime.strptime(r['published'][:10], '%Y-%m-%d').date()\n",
    "            print(paper_date)\n",
    "            print(today- timedelta(1))\n",
    "            if paper_date >= today - timedelta(1):\n",
    "                new_papers_found = True\n",
    "                paper_list.append(Document(text=f\"\"\"\n",
    "Title: {clean_text(r['title'])}\n",
    "{r['summary']}\n",
    "                \"\"\", metadata={'paper_id': r['id'].split(\"/\")[-1], 'title': clean_text(r['title']), 'date': r['published'][:10]}))\n",
    "                new_paper += 1\n",
    "                \n",
    "        if new_paper == 0:\n",
    "            new_papers_found = False\n",
    "        \n",
    "        start += max_results\n",
    "        time.sleep(wait_time)\n",
    "\n",
    "    return paper_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-14\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-13\n",
      "2024-05-16\n",
      "2024-05-12\n",
      "2024-05-16\n",
      "2024-05-12\n",
      "2024-05-16\n",
      "2024-05-12\n",
      "2024-05-16\n",
      "2024-05-12\n",
      "2024-05-16\n",
      "2024-05-12\n",
      "2024-05-16\n",
      "2024-05-12\n",
      "2024-05-16\n"
     ]
    }
   ],
   "source": [
    "paper_list = get_daily_arxiv_papers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paper_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import MetadataMode\n",
    "daily_paper_content = \"\\n===============\\n\".join([paper.get_content(MetadataMode.LLM) for paper in paper_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionResponse(text='Hi! ðŸ‘‹  What can I do for you today? ðŸ˜Š \\n', additional_kwargs={}, raw={'content': {'parts': [{'text': 'Hi! ðŸ‘‹  What can I do for you today? ðŸ˜Š \\n'}], 'role': 'model'}, 'finish_reason': 1, 'index': 0, 'safety_ratings': [], 'token_count': 0, 'grounding_attributions': [], 'block_reason': 0}, logprobs=None, delta=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.llms.gemini import Gemini\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "gemini = Gemini(model_name=\"models/gemini-1.5-flash-latest\", api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "gemini.complete(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are a professional researcher in the field of AI. You are given a list of paper abstract in one day.\n",
    "Your job is to summarize the trends and note out some most interesting papers in the list. \n",
    "Give the link to the full paper in the report.\n",
    "===============\n",
    "{daily_paper_content}\n",
    "\"\"\"\n",
    "\n",
    "response = gemini.complete(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## AI Research Paper Trends: May 14, 2024\n",
       "\n",
       "This report summarizes trends and highlights interesting papers from a list of AI research abstracts published on May 14, 2024.\n",
       "\n",
       "**Trends:**\n",
       "\n",
       "* **Multimodal Learning:** There is a strong focus on multimodal learning, particularly combining vision and language. This includes papers on vision-language pre-training, scientific figure interpretation, and multimodal large language models for medical applications.\n",
       "* **Robustness and Generalization:** Many papers address the challenges of robustness and generalization in AI models. This includes work on out-of-distribution detection, domain generalization, and improving the robustness of models to data variations.\n",
       "* **Explainability and Fairness:**  There is growing interest in making AI models more explainable and fair. Papers explore methods for explaining model decisions, mitigating bias in medical image classification, and ensuring fairness in channel pruning.\n",
       "* **Reinforcement Learning:**  Reinforcement learning continues to be a popular area of research, with papers focusing on improving efficiency, addressing challenges in offline RL, and applying RL to real-world problems like autonomous intersection management and option hedging.\n",
       "* **Large Language Models:**  LLMs are being applied to a wide range of tasks, including text-to-image generation, scientific figure interpretation, and enhancing the accessibility of legal documents.\n",
       "\n",
       "**Most Interesting Papers:**\n",
       "\n",
       "* **SciFIBench: Benchmarking Large Multimodal Models for Scientific Figure Interpretation** ([http://arxiv.org/abs/2405.08807v1](http://arxiv.org/abs/2405.08807v1)): This paper introduces a new benchmark for evaluating the ability of large multimodal models to understand and interpret scientific figures. This is a crucial area for AI to assist scientific research.\n",
       "* **CinePile: A Long Video Question Answering Dataset and Benchmark** ([http://arxiv.org/abs/2405.08813v1](http://arxiv.org/abs/2405.08813v1)): This paper presents a new dataset and benchmark for long-form video understanding, which is a challenging task for current AI models. The dataset is designed to test genuine long-form comprehension, not just analyzing a few frames.\n",
       "* **EfficientTrain++: Generalized Curriculum Learning for Efficient Visual Backbone Training** ([http://arxiv.org/abs/2405.08768v1](http://arxiv.org/abs/2405.08768v1)): This paper proposes a novel approach to curriculum learning that significantly reduces the training time of visual backbones without sacrificing accuracy. This is a valuable contribution to making AI models more efficient.\n",
       "* **Hunyuan-DiT: A Powerful Multi-Resolution Diffusion Transformer with Fine-Grained Chinese Understanding** ([http://arxiv.org/abs/2405.08748v1](http://arxiv.org/abs/2405.08748v1)): This paper presents a new text-to-image diffusion transformer that demonstrates fine-grained understanding of both English and Chinese. This is a significant step towards developing more multilingual and culturally sensitive AI models.\n",
       "* **Promoting AI Equity in Science: Generalized Domain Prompt Learning for Accessible VLM Research** ([http://arxiv.org/abs/2405.08668v1](http://arxiv.org/abs/2405.08668v1)): This paper proposes a framework for adapting vision-language models to specialized domains without requiring extensive data or resources. This is a crucial step towards making AI research more accessible and equitable.\n",
       "\n",
       "**Overall, this day's research highlights the rapid progress being made in AI, particularly in areas like multimodal learning, robustness, explainability, and fairness. These advancements are paving the way for AI to play an increasingly important role in various fields, from scientific research to healthcare and beyond.** \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../outputs/daily_report_may_14.md\", \"w\") as f:\n",
    "    f.write(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = \"\"\"\n",
    "## AI Research Paper Trends and Interesting Papers: 2024-05-14\n",
    "\n",
    "This report summarizes trends and highlights interesting papers from a list of AI research abstracts published on 2024-05-14.\n",
    "\n",
    "**Trends:**\n",
    "\n",
    "* **Large Language Models (LLMs) are increasingly being used for various tasks:** This includes tasks like question answering, text generation, code completion, and even medical diagnosis. \n",
    "* **Multimodal learning is gaining traction:** Researchers are exploring ways to combine different types of data, such as text, images, and audio, to improve model performance.\n",
    "* **Focus on robustness and safety:** Researchers are working on making AI models more robust to adversarial attacks and ensuring their safe deployment in real-world applications.\n",
    "* **Addressing bias in AI models:** Researchers are developing methods to mitigate bias in AI models, particularly in sensitive domains like healthcare.\n",
    "* **Improving efficiency and scalability:** Researchers are working on making AI models more efficient and scalable, particularly for use on mobile devices and in large-scale applications.\n",
    "\n",
    "**Most Interesting Papers:**\n",
    "\n",
    "* **Paper ID: 2405.08760v1 - \"Is the Pope Catholic? Yes, the Pope is Catholic. Generative Evaluation of Intent Resolution in LLMs\"**\n",
    "    * This paper explores the challenges of evaluating LLMs' ability to understand non-literal language and intentions. The findings highlight the need for better approaches to model intentions and utilize them for pragmatic generation.\n",
    "    * **Link:** [https://arxiv.org/abs/2405.08760](https://arxiv.org/abs/2405.08760)\n",
    "* **Paper ID: 2405.08755v1 - \"Distributed Threat Intelligence at the Edge Devices: A Large Language Model-Driven Approach\"**\n",
    "    * This paper proposes a novel approach to enhance cybersecurity at the edge by leveraging LLMs for distributed threat intelligence. The approach offers a promising solution for combating emerging cyber threats in decentralized environments.\n",
    "    * **Link:** [https://arxiv.org/abs/2405.08755](https://arxiv.org/abs/2405.08755)\n",
    "* **Paper ID: 2405.08668v1 - \"Promoting AI Equity in Science: Generalized Domain Prompt Learning for Accessible VLM Research\"**\n",
    "    * This paper presents a framework for adapting VLMs to specialized domains without requiring extensive data or resources. This approach promotes sustainable and equitable VLM research, making it more accessible to academic researchers.\n",
    "    * **Link:** [https://arxiv.org/abs/2405.08668](https://arxiv.org/abs/2405.08668)\n",
    "* **Paper ID: 2405.08487v1 - \"Enhancing Gender-Inclusive Machine Translation with Neomorphemes and Large Language Models\"**\n",
    "    * This paper explores the use of neomorphemes (gender-neutral language elements) to improve gender inclusivity in machine translation. The research introduces a new evaluation resource and investigates the effectiveness of different LLMs and prompting techniques.\n",
    "    * **Link:** [https://arxiv.org/abs/2405.08487](https://arxiv.org/abs/2405.08487)\n",
    "* **Paper ID: 2405.08355v1 - \"Seal-Tools: Self-Instruct Tool Learning Dataset for Agent Tuning and Detailed Benchmark\"**\n",
    "    * This paper introduces a new dataset for evaluating the tool-calling ability of LLMs. The dataset includes self-instruct API-like tools and instances demonstrating their practical application. This benchmark can help researchers assess the progress of LLMs in tool learning.\n",
    "    * **Link:** [https://arxiv.org/abs/2405.08355](https://arxiv.org/abs/2405.08355)\n",
    "\n",
    "This list is not exhaustive, and there are many other interesting papers published on this date. However, these papers represent some of the most exciting and impactful research in the field of AI. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h2>AI Research Paper Trends and Interesting Papers: 2024-05-14</h2>\n",
      "<p>This report summarizes trends and highlights interesting papers from a list of AI research abstracts published on 2024-05-14.</p>\n",
      "<p><strong>Trends:</strong></p>\n",
      "<ul>\n",
      "<li><strong>Large Language Models (LLMs) are increasingly being used for various tasks:</strong> This includes tasks like question answering, text generation, code completion, and even medical diagnosis. </li>\n",
      "<li><strong>Multimodal learning is gaining traction:</strong> Researchers are exploring ways to combine different types of data, such as text, images, and audio, to improve model performance.</li>\n",
      "<li><strong>Focus on robustness and safety:</strong> Researchers are working on making AI models more robust to adversarial attacks and ensuring their safe deployment in real-world applications.</li>\n",
      "<li><strong>Addressing bias in AI models:</strong> Researchers are developing methods to mitigate bias in AI models, particularly in sensitive domains like healthcare.</li>\n",
      "<li><strong>Improving efficiency and scalability:</strong> Researchers are working on making AI models more efficient and scalable, particularly for use on mobile devices and in large-scale applications.</li>\n",
      "</ul>\n",
      "<p><strong>Most Interesting Papers:</strong></p>\n",
      "<ul>\n",
      "<li><strong>Paper ID: 2405.08760v1 - \"Is the Pope Catholic? Yes, the Pope is Catholic. Generative Evaluation of Intent Resolution in LLMs\"</strong><ul>\n",
      "<li>This paper explores the challenges of evaluating LLMs' ability to understand non-literal language and intentions. The findings highlight the need for better approaches to model intentions and utilize them for pragmatic generation.</li>\n",
      "<li><strong>Link:</strong> <a href=\"https://arxiv.org/abs/2405.08760\">https://arxiv.org/abs/2405.08760</a></li>\n",
      "</ul>\n",
      "</li>\n",
      "<li><strong>Paper ID: 2405.08755v1 - \"Distributed Threat Intelligence at the Edge Devices: A Large Language Model-Driven Approach\"</strong><ul>\n",
      "<li>This paper proposes a novel approach to enhance cybersecurity at the edge by leveraging LLMs for distributed threat intelligence. The approach offers a promising solution for combating emerging cyber threats in decentralized environments.</li>\n",
      "<li><strong>Link:</strong> <a href=\"https://arxiv.org/abs/2405.08755\">https://arxiv.org/abs/2405.08755</a></li>\n",
      "</ul>\n",
      "</li>\n",
      "<li><strong>Paper ID: 2405.08668v1 - \"Promoting AI Equity in Science: Generalized Domain Prompt Learning for Accessible VLM Research\"</strong><ul>\n",
      "<li>This paper presents a framework for adapting VLMs to specialized domains without requiring extensive data or resources. This approach promotes sustainable and equitable VLM research, making it more accessible to academic researchers.</li>\n",
      "<li><strong>Link:</strong> <a href=\"https://arxiv.org/abs/2405.08668\">https://arxiv.org/abs/2405.08668</a></li>\n",
      "</ul>\n",
      "</li>\n",
      "<li><strong>Paper ID: 2405.08487v1 - \"Enhancing Gender-Inclusive Machine Translation with Neomorphemes and Large Language Models\"</strong><ul>\n",
      "<li>This paper explores the use of neomorphemes (gender-neutral language elements) to improve gender inclusivity in machine translation. The research introduces a new evaluation resource and investigates the effectiveness of different LLMs and prompting techniques.</li>\n",
      "<li><strong>Link:</strong> <a href=\"https://arxiv.org/abs/2405.08487\">https://arxiv.org/abs/2405.08487</a></li>\n",
      "</ul>\n",
      "</li>\n",
      "<li><strong>Paper ID: 2405.08355v1 - \"Seal-Tools: Self-Instruct Tool Learning Dataset for Agent Tuning and Detailed Benchmark\"</strong><ul>\n",
      "<li>This paper introduces a new dataset for evaluating the tool-calling ability of LLMs. The dataset includes self-instruct API-like tools and instances demonstrating their practical application. This benchmark can help researchers assess the progress of LLMs in tool learning.</li>\n",
      "<li><strong>Link:</strong> <a href=\"https://arxiv.org/abs/2405.08355\">https://arxiv.org/abs/2405.08355</a></li>\n",
      "</ul>\n",
      "</li>\n",
      "</ul>\n",
      "<p>This list is not exhaustive, and there are many other interesting papers published on this date. However, these papers represent some of the most exciting and impactful research in the field of AI. </p>\n"
     ]
    }
   ],
   "source": [
    "import markdown\n",
    "\n",
    "print(markdown.markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
